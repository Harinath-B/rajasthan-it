{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/hari/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import math, copy, sys\n",
    "\n",
    "import torch\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet') \n",
    "\n",
    "from scripts.MoveData import *\n",
    "from scripts.Transformer import *\n",
    "from scripts.TalkTrain import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Options(batchsize=16, device=torch.device(\"cuda\"), epochs=40, \n",
    "              lr=0.01, max_len = 40, save_path = 'data/transformer_custom_weights')\n",
    "\n",
    "data_iter, infield, outfield, opt = json2datatools(path = 'data/data1.json', opt=opt)\n",
    "print('input vocab size', len(infield.vocab), 'output vocab size', len(outfield.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim, n_layers, heads, dropout = 32, 2, 8, 0.1 \n",
    "dole = Transformer(len(infield.vocab), len(outfield.vocab), emb_dim, n_layers, heads, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(dole.parameters(), lr=opt.lr, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, data_iterator, options, optimizer, scheduler):\n",
    "\n",
    "    if torch.cuda.is_available() and options.device == torch.device(\"cuda:0\"):\n",
    "        print(\"a GPU was detected, model will be trained on GPU\")\n",
    "        model = model.cuda()\n",
    "    else:\n",
    "        print(\"training on cpu\")\n",
    "\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    best_loss = 100\n",
    "    for epoch in range(options.epochs):\n",
    "        total_loss = 0\n",
    "        for i, batch in enumerate(data_iterator): \n",
    "            src = batch.listen.transpose(0,1)\n",
    "            trg = batch.reply.transpose(0,1)\n",
    "            trg_input = trg[:, :-1]\n",
    "            src_mask, trg_mask = create_masks(src, trg_input, options)\n",
    "            preds = model(src, src_mask, trg_input, trg_mask)\n",
    "            ys = trg[:, 1:].contiguous().view(-1)\n",
    "            optimizer.zero_grad()\n",
    "            preds = preds.view(-1, preds.size(-1))\n",
    "            batch_loss = F.cross_entropy(preds, ys, \n",
    "                                         ignore_index = options.trg_pad)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += batch_loss.item()\n",
    "\n",
    "        epoch_loss = total_loss/(num_batches(data_iterator)+1)\n",
    "        scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            print(f'saving model at', options.save_path)\n",
    "            torch.save(model.state_dict(), options.save_path)\n",
    "            \n",
    "        print(\"%dm: epoch %d loss = %.3f\" %((time.time() - start)//60, epoch, epoch_loss))\n",
    "        total_loss = 0\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dole = trainer(dole, data_iter, opt, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
